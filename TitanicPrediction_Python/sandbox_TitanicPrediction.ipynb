{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Survived  Pclass  Sex     Age  SibSp  Parch      Fare\n",
      "0           0       2    0  35.000      0      0   26.0000\n",
      "1           1       3    1  38.000      1      5   31.3875\n",
      "2           0       1    0  19.000      3      2  263.0000\n",
      "3           1       3    0  29.125      0      0    7.2292\n",
      "4           0       3    1  40.000      1      0    9.4750\n",
      "..        ...     ...  ...     ...    ...    ...       ...\n",
      "155         0       3    1   9.000      1      1   15.2458\n",
      "156         1       3    0   4.000      1      1   11.1333\n",
      "157         0       1    0  33.000      0      0    5.0000\n",
      "158         1       1    1  19.000      0      0   30.0000\n",
      "159         0       3    0  32.000      0      0    7.7500\n",
      "\n",
      "[160 rows x 7 columns]\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U8'), dtype('float64')) -> None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb Cell 1\u001b[0m line \u001b[0;36m<cell line: 76>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=72'>73</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m predictions\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=74'>75</a>\u001b[0m X_test \u001b[39m=\u001b[39m df_test\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=75'>76</a>\u001b[0m predictions \u001b[39m=\u001b[39m knn(X_train, y_train, X_test, k\u001b[39m=\u001b[39;49m\u001b[39m3\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=76'>77</a>\u001b[0m \u001b[39mprint\u001b[39m(predictions)\n",
      "\u001b[1;32m/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb Cell 1\u001b[0m line \u001b[0;36mknn\u001b[0;34m(X_train, y_train, X_test, k)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=61'>62</a>\u001b[0m distances \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mfor\u001b[39;00m train_point \u001b[39min\u001b[39;00m X_train:\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=63'>64</a>\u001b[0m     dist \u001b[39m=\u001b[39m euclidean_distance(test_point, train_point)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=64'>65</a>\u001b[0m     distances\u001b[39m.\u001b[39mappend((dist, train_point))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=65'>66</a>\u001b[0m \u001b[39m# Sort the distances and select the k nearest neighbors\u001b[39;00m\n",
      "\u001b[1;32m/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb Cell 1\u001b[0m line \u001b[0;36meuclidean_distance\u001b[0;34m(p, q)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meuclidean_distance\u001b[39m(p, q):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/sandbox_TitanicPrediction.ipynb#W0sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39mnorm(p \u001b[39m-\u001b[39;49m q)\n",
      "\u001b[0;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U8'), dtype('float64')) -> None"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "\n",
    "# testing model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# testing model \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "# import training data using specified path\n",
    "df_train = pd.read_csv('/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/Data/train.csv')\n",
    "#print(df_train)\n",
    "\n",
    "df_test = pd.read_csv('/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/Data/test.csv')\n",
    "#print(df_test)\n",
    "\n",
    "# drop useless attributes for now and change categorical vars to numerical\n",
    "df_train.drop(labels = [\"Cabin\", \"Embarked\", \"Name\", \"PassengerId\", \"Ticket\"], inplace = True, axis = 1)\n",
    "# replace sex with 0 for male, 1 for female\n",
    "df_train['Sex'].replace(['male', 'female'], [0, 1], inplace = True)\n",
    "\n",
    "# fill in age values with average\n",
    "df_train['Age'].fillna(df_train['Age'].mean(), inplace=True)\n",
    "#print(df_train)\n",
    "\n",
    "# drop useless attributes for now and change categorical vars to numerical\n",
    "df_test.drop(labels = [\"Cabin\", \"Embarked\", \"Name\", \"PassengerId\", \"Ticket\"], inplace = True, axis = 1)\n",
    "# replace sex with 0 for male, 1 for female\n",
    "df_test['Sex'].replace(['male', 'female'], [0, 1], inplace = True)\n",
    "\n",
    "# fill in age values with average\n",
    "df_test['Age'].fillna(df_test['Age'].mean(), inplace=True)\n",
    "#print(df_test)\n",
    "\n",
    "def euclidean_distance(p, q):\n",
    "    return np.linalg.norm(p - q);\n",
    "\n",
    "X_train = df_train.drop(\"Survived\", axis=1).values\n",
    "y_train = df_train[\"Survived\"].values\n",
    "\n",
    "X_test = df_test.drop(\"Survived\", axis=1).values\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "#print(X_test)\n",
    "\n",
    "def knn(X_train, y_train, X_test, k):\n",
    "    predictions = []\n",
    "    for test_point in X_test:\n",
    "        distances = []\n",
    "        for train_point in X_train:\n",
    "            dist = euclidean_distance(test_point, train_point)\n",
    "            distances.append((dist, train_point))\n",
    "        # Sort the distances and select the k nearest neighbors\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        neighbors = [neighbor for _, neighbor in distances[:k]]\n",
    "        # Count the class labels of the k nearest neighbors\n",
    "        counts = np.bincount(y_train[neighbors])\n",
    "        # Predict the class with the majority vote\n",
    "        predictions.append(np.argmax(counts))\n",
    "    return predictions\n",
    "\n",
    "X_test = df_test\n",
    "predictions = knn(X_train, y_train, X_test, k=3)\n",
    "print(predictions)\n",
    "\n",
    "#print(\"Accuracy:\", accuracy_score(y_test, predictions))\n",
    "#print(\"F1 Score:\", f1_score(y_test, predictions))\n",
    "#print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, predictions))\n",
    "#print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n",
      "Passenger ID 1, Survived = 0\n",
      "Passenger ID 2, Survived = 0\n",
      "Passenger ID 3, Survived = 1\n",
      "Passenger ID 4, Survived = 0\n",
      "Passenger ID 5, Survived = 0\n",
      "Passenger ID 6, Survived = 1\n",
      "Passenger ID 7, Survived = 0\n",
      "Passenger ID 8, Survived = 0\n",
      "Passenger ID 9, Survived = 0\n",
      "Passenger ID 10, Survived = 0\n",
      "Passenger ID 11, Survived = 0\n",
      "Passenger ID 12, Survived = 1\n",
      "Passenger ID 13, Survived = 0\n",
      "Passenger ID 14, Survived = 0\n",
      "Passenger ID 15, Survived = 0\n",
      "Passenger ID 16, Survived = 0\n",
      "Passenger ID 17, Survived = 1\n",
      "Passenger ID 18, Survived = 0\n",
      "Passenger ID 19, Survived = 1\n",
      "Passenger ID 20, Survived = 0\n",
      "Passenger ID 21, Survived = 0\n",
      "Passenger ID 22, Survived = 0\n",
      "Passenger ID 23, Survived = 0\n",
      "Passenger ID 24, Survived = 0\n",
      "Passenger ID 25, Survived = 0\n",
      "Passenger ID 26, Survived = 0\n",
      "Passenger ID 27, Survived = 0\n",
      "Passenger ID 28, Survived = 0\n",
      "Passenger ID 29, Survived = 1\n",
      "Passenger ID 30, Survived = 0\n",
      "Passenger ID 31, Survived = 1\n",
      "Passenger ID 32, Survived = 0\n",
      "Passenger ID 33, Survived = 0\n",
      "Passenger ID 34, Survived = 0\n",
      "Passenger ID 35, Survived = 0\n",
      "Passenger ID 36, Survived = 0\n",
      "Passenger ID 37, Survived = 1\n",
      "Passenger ID 38, Survived = 0\n",
      "Passenger ID 39, Survived = 0\n",
      "Passenger ID 40, Survived = 0\n",
      "Passenger ID 41, Survived = 0\n",
      "Passenger ID 42, Survived = 0\n",
      "Passenger ID 43, Survived = 1\n",
      "Passenger ID 44, Survived = 1\n",
      "Passenger ID 45, Survived = 1\n",
      "Passenger ID 46, Survived = 0\n",
      "Passenger ID 47, Survived = 0\n",
      "Passenger ID 48, Survived = 0\n",
      "Passenger ID 49, Survived = 0\n",
      "Passenger ID 50, Survived = 1\n",
      "Passenger ID 51, Survived = 1\n",
      "Passenger ID 52, Survived = 1\n",
      "Passenger ID 53, Survived = 0\n",
      "Passenger ID 54, Survived = 0\n",
      "Passenger ID 55, Survived = 0\n",
      "Passenger ID 56, Survived = 0\n",
      "Passenger ID 57, Survived = 1\n",
      "Passenger ID 58, Survived = 0\n",
      "Passenger ID 59, Survived = 1\n",
      "Passenger ID 60, Survived = 1\n",
      "Passenger ID 61, Survived = 0\n",
      "Passenger ID 62, Survived = 0\n",
      "Passenger ID 63, Survived = 1\n",
      "Passenger ID 64, Survived = 1\n",
      "Passenger ID 65, Survived = 1\n",
      "Passenger ID 66, Survived = 0\n",
      "Passenger ID 67, Survived = 1\n",
      "Passenger ID 68, Survived = 1\n",
      "Passenger ID 69, Survived = 1\n",
      "Passenger ID 70, Survived = 0\n",
      "Passenger ID 71, Survived = 1\n",
      "Passenger ID 72, Survived = 0\n",
      "Passenger ID 73, Survived = 0\n",
      "Passenger ID 74, Survived = 1\n",
      "Passenger ID 75, Survived = 0\n",
      "Passenger ID 76, Survived = 0\n",
      "Passenger ID 77, Survived = 0\n",
      "Passenger ID 78, Survived = 1\n",
      "Passenger ID 79, Survived = 1\n",
      "Passenger ID 80, Survived = 0\n",
      "Passenger ID 81, Survived = 0\n",
      "Passenger ID 82, Survived = 0\n",
      "Passenger ID 83, Survived = 0\n",
      "Passenger ID 84, Survived = 0\n",
      "Passenger ID 85, Survived = 0\n",
      "Passenger ID 86, Survived = 1\n",
      "Passenger ID 87, Survived = 0\n",
      "Passenger ID 88, Survived = 0\n",
      "Passenger ID 89, Survived = 0\n",
      "Passenger ID 90, Survived = 1\n",
      "Passenger ID 91, Survived = 0\n",
      "Passenger ID 92, Survived = 0\n",
      "Passenger ID 93, Survived = 0\n",
      "Passenger ID 94, Survived = 1\n",
      "Passenger ID 95, Survived = 0\n",
      "Passenger ID 96, Survived = 0\n",
      "Passenger ID 97, Survived = 0\n",
      "Passenger ID 98, Survived = 1\n",
      "Passenger ID 99, Survived = 0\n",
      "Passenger ID 100, Survived = 1\n",
      "Passenger ID 101, Survived = 0\n",
      "Passenger ID 102, Survived = 0\n",
      "Passenger ID 103, Survived = 0\n",
      "Passenger ID 104, Survived = 0\n",
      "Passenger ID 105, Survived = 0\n",
      "Passenger ID 106, Survived = 0\n",
      "Passenger ID 107, Survived = 0\n",
      "Passenger ID 108, Survived = 0\n",
      "Passenger ID 109, Survived = 0\n",
      "Passenger ID 110, Survived = 0\n",
      "Passenger ID 111, Survived = 0\n",
      "Passenger ID 112, Survived = 0\n",
      "Passenger ID 113, Survived = 0\n",
      "Passenger ID 114, Survived = 0\n",
      "Passenger ID 115, Survived = 0\n",
      "Passenger ID 116, Survived = 0\n",
      "Passenger ID 117, Survived = 0\n",
      "Passenger ID 118, Survived = 0\n",
      "Passenger ID 119, Survived = 1\n",
      "Passenger ID 120, Survived = 1\n",
      "Passenger ID 121, Survived = 1\n",
      "Passenger ID 122, Survived = 0\n",
      "Passenger ID 123, Survived = 0\n",
      "Passenger ID 124, Survived = 1\n",
      "Passenger ID 125, Survived = 1\n",
      "Passenger ID 126, Survived = 0\n",
      "Passenger ID 127, Survived = 0\n",
      "Passenger ID 128, Survived = 1\n",
      "Passenger ID 129, Survived = 0\n",
      "Passenger ID 130, Survived = 0\n",
      "Passenger ID 131, Survived = 0\n",
      "Passenger ID 132, Survived = 1\n",
      "Passenger ID 133, Survived = 1\n",
      "Passenger ID 134, Survived = 0\n",
      "Passenger ID 135, Survived = 1\n",
      "Passenger ID 136, Survived = 0\n",
      "Passenger ID 137, Survived = 0\n",
      "Passenger ID 138, Survived = 0\n",
      "Passenger ID 139, Survived = 1\n",
      "Passenger ID 140, Survived = 0\n",
      "Passenger ID 141, Survived = 0\n",
      "Passenger ID 142, Survived = 0\n",
      "Passenger ID 143, Survived = 0\n",
      "Passenger ID 144, Survived = 1\n",
      "Passenger ID 145, Survived = 1\n",
      "Passenger ID 146, Survived = 0\n",
      "Passenger ID 147, Survived = 0\n",
      "Passenger ID 148, Survived = 1\n",
      "Passenger ID 149, Survived = 0\n",
      "Passenger ID 150, Survived = 0\n",
      "Passenger ID 151, Survived = 1\n",
      "Passenger ID 152, Survived = 0\n",
      "Passenger ID 153, Survived = 0\n",
      "Passenger ID 154, Survived = 0\n",
      "Passenger ID 155, Survived = 0\n",
      "Passenger ID 156, Survived = 1\n",
      "Passenger ID 157, Survived = 1\n",
      "Passenger ID 158, Survived = 0\n",
      "Passenger ID 159, Survived = 1\n",
      "Passenger ID 160, Survived = 0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "\n",
    "# Load the training and test data\n",
    "df_train = pd.read_csv('/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/Data/train.csv')\n",
    "df_test = pd.read_csv('/Users/nwilson/Documents/GitHub/cscd429/TitanicPrediction_Python/Data/test.csv')\n",
    "\n",
    "# Drop irrelevant columns and handle categorical variables\n",
    "df_train.drop(labels=[\"Cabin\", \"Embarked\", \"Name\", \"PassengerId\", \"Ticket\"], inplace=True, axis=1)\n",
    "df_train['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\n",
    "df_train['Age'].fillna(df_train['Age'].mean(), inplace=True)\n",
    "\n",
    "df_test.drop(labels=[\"Cabin\", \"Embarked\", \"Name\", \"PassengerId\", \"Ticket\"], inplace=True, axis=1)\n",
    "df_test['Sex'].replace(['male', 'female'], [0, 1], inplace=True)\n",
    "df_test['Age'].fillna(df_test['Age'].mean(), inplace=True)\n",
    "\n",
    "X_train_data = df_train.drop(\"Survived\", axis=1).values\n",
    "Y_train_data = df_train[\"Survived\"].values\n",
    "X_test_data = df_test.drop(\"Survived\", axis=1).values\n",
    "Y_test_data = df_test[\"Survived\"].values\n",
    "\n",
    "class k_nearest_neighbors:\n",
    "\n",
    "    def __init__(self, k):\n",
    "        self.k=k\n",
    "\n",
    "    def fit_data(self, X_train_data, Y_train_data):\n",
    "        self.X_train_data = X_train_data\n",
    "        self.Y_train_data = Y_train_data\n",
    "\n",
    "    def euclidean_distance(self, x, y):\n",
    "        return np.linalg.norm(x - y)\n",
    "    \n",
    "    def get_distance(item):\n",
    "        return item[1]\n",
    "    \n",
    "    def find_nearest_neighbors(self, tupl):\n",
    "        \n",
    "        # want to find the nearest neighbors \n",
    "        # for each data point\n",
    "\n",
    "        distances = []\n",
    "\n",
    "        # calculate distances using i as an index \n",
    "        # for each distance\n",
    "        for i in range(len(self.X_train_data)):\n",
    "            distances.append((i, self.euclidean_distance(self.X_train_data[i], tupl)))\n",
    "    \n",
    "        # sort by distance \n",
    "        distances.sort(key=lambda x: x[1])\n",
    "\n",
    "        # return ids and distances of top neighbors\n",
    "        return distances[:self.k]\n",
    "   \n",
    "    def predict(self, X_train_data):\n",
    "\n",
    "        predictions = []\n",
    "\n",
    "        # \n",
    "        for i in range(len(X_train_data)):\n",
    "            \n",
    "            neighbors = self.find_nearest_neighbors(X_train_data[i])\n",
    "            \n",
    "            y_vals = [self.Y_train_data[j[0]] for j in neighbors]\n",
    "            \n",
    "            prediction = (sum(y_values) / self.k)\n",
    "\n",
    "            if(prediction <= 0.5):\n",
    "                prediction = 0\n",
    "            else:\n",
    "                prediction = 1\n",
    "\n",
    "            predictions.append(prediction)\n",
    "            \n",
    "        \n",
    "        #most_common = Counter(predictions).most_common()\n",
    "\n",
    "        return predictions\n",
    "    \n",
    "\n",
    "\n",
    "model = k_nearest_neighbors(k=13)\n",
    "model.fit_data(X_train_data, Y_train_data)\n",
    "predictions = model.predict(X_test_data)\n",
    "\n",
    "print(predictions)\n",
    "\n",
    "\n",
    "for i in range(0, len(predictions)):\n",
    "    print(f\"Passenger ID {i+1}, Survived = {predictions[i]}\")\n",
    "\n",
    "#for idx, prediction in predictions:\n",
    "#    print(f\"Passenger ID {prediction}: Predicted Class = {idx}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
